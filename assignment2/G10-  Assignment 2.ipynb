{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors, linear_model\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "import pydot\n",
    "\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question I: Revisiting HW4 Bank Classi\f",
    "cation with New Tools (for dataset A) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Loading the dataset and performing data preprocessing\n",
    "\n",
    "> Load a simple dataset and perform some basic data preprocessing to fill out ”unknowns”,\n",
    "outliers or other invalid data. Explain what preprocessing was performed and why. Also,\n",
    "change categorical data into numerical features using pandas.get dummies [5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_addidtional_full = \"bank-additional.csv\"\n",
    "\n",
    "data = pd.read_csv(bank_addidtional_full, sep = ';', na_values=[\"unknown\"])\n",
    "df = pd.DataFrame(data)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first check for missing values in the dataset. There was 1230 entries as unknown in the catogerical features that were replaced with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum().sum())\n",
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN values were replaced by the mode of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we convert all the catogrical columns to numerical columns. Also, dropping the duration column since is a predictive variable according to UCI website and should be dropped if the purpose is to build a realistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df._get_numeric_data().head()\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})\n",
    "df.drop(['duration'], axis=1, inplace=True)\n",
    "df = pd.get_dummies(df,drop_first=True)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df.columns.values) #Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('y')) #Remove y from list\n",
    "df = df[cols + ['y']] #Create new dataframe with columns in the order you want\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to UCI dataset description, the pdays columns (which represents the number of days passed by after the client was last contacted from a previous campaign) has some 999 values which means that client was not previously contacted. We replaced these 999 values with 0 since samples with 999 entries would be considered as an outliers when it comes to data cleaning. There was found to be 3,959 samples in the pdays column that had to be replaced with 0 instead of 999\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['pdays'])\n",
    "df['pdays'].value_counts()\n",
    "# data['pdays'].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.pdays = df.pdays.replace({999: np.nan })\n",
    "# display(df.pdays.describe())\n",
    "# sns.boxplot(x=df['pdays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.pdays = df.pdays.fillna(df.pdays.mean() + df.pdays.std()*6)\n",
    "# sns.boxplot(x=df['pdays'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now detecting the outliers and keeping samples that are only within 3 standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]\n",
    "# keep only the ones that are within +3 to -3 standard deviations in the column 'Data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Dividing data into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and test data. The test data size chosen to be 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('y',axis=1)\n",
    "y = df['y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Applying classification: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, the classifier was instantiated with the default parameters and then was tuned later for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=101)\n",
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtree.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC is plotted below to check for overfitting cases with depth of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "   dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "   dt.fit(X_train, y_train)\n",
    "   train_pred = dt.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous train results\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = dt.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   # Add auc score to previous test results\n",
    "   test_results.append(roc_auc)\n",
    "    \n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.show()\n",
    "#Source: https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the graph above, we see that when we have a high tree depth we get an overfitting case where the model can predicts the train data perfectly (high area under curve), however, the models fails to generalize and predict new data (test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100, max_depth=3, min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy is \", accuracy_score(y_test,y_pred_dt)*100)\n",
    "print(confusion_matrix(y_test,y_pred_dt))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "# train_results = []\n",
    "# test_results = []\n",
    "# for min_samples_split in min_samples_splits:\n",
    "#    dt = DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
    "#    dt.fit(X_train, y_train)\n",
    "#    train_pred = dt.predict(X_train)\n",
    "#    false_positive_rate, true_positive_rate, thresholds =    roc_curve(y_train, train_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    train_results.append(roc_auc)\n",
    "#    y_pred = dt.predict(X_test)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    test_results.append(roc_auc)\n",
    "# from matplotlib.legend_handler import HandlerLine2D\n",
    "# line1, = plt.plot(min_samples_splits, train_results, 'b', label=\"Train AUC\")\n",
    "# line2, = plt.plot(min_samples_splits, test_results, 'r', label=\"Test AUC\")\n",
    "# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "# plt.ylabel('AUC score')\n",
    "# plt.xlabel('min samples split')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "# train_results = []\n",
    "# test_results = []\n",
    "# for min_samples_leaf in min_samples_leafs:\n",
    "#    dt = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)\n",
    "#    dt.fit(X_train, y_train)\n",
    "#    train_pred = dt.predict(X_train)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    train_results.append(roc_auc)\n",
    "#    y_pred = dt.predict(X_test)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    test_results.append(roc_auc)\n",
    "# from matplotlib.legend_handler import HandlerLine2D\n",
    "# line1, = plt.plot(min_samples_leafs, train_results, 'b', label=\"Train AUC\")\n",
    "# line2, = plt.plot(min_samples_leafs, test_results, 'r', label=\"Test AUC\")\n",
    "# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "# plt.ylabel('AUC score')\n",
    "# plt.xlabel('min samples leaf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Visualization using the the built-in visualization from Scikit learn. This requires to install the pydot library and Graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot \n",
    "\n",
    "features = list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()  \n",
    "export_graphviz(clf_gini, out_file=dot_data,feature_names=features,filled=True,rounded=True)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph[0].create_png()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Random Forests (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first fit the model with default parameters and evaluate the performance, then we will tune the parameters and compare the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=101)\n",
    "rfc_clf = rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy is \", accuracy_score(y_test,rfc_pred)*100)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to DT classifier, we will use the area under curve AUC to evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for estimator in n_estimators:\n",
    "   rf = RandomForestClassifier(n_estimators=estimator, n_jobs=-1, random_state=101)\n",
    "   rf.fit(X_train, y_train)\n",
    "   train_pred = rf.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "\n",
    "    \n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.show()\n",
    "# Source: https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The n_estimators in the random forests classifier represents the numsber of trees used in the classifier. Based on the AUC graph above, we see that the highest AUC score for the test data will be around 16 n_estimators. Increasing the n_estimators decreases the test perfomance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "   rf = RandomForestClassifier(max_depth=max_depth, n_jobs=-1, random_state=101)\n",
    "   rf.fit(X_train, y_train)\n",
    "   train_pred = rf.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.show()\n",
    "#Source: https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the higher the tree depth, we get an overfitting case. So a tree depth of 3 wil be chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=16,random_state=101, max_depth=3)\n",
    "RFC_clf = RFC.fit(X_train, y_train)\n",
    "RFC_pred = RFC.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Results from the default parameters:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,rfc_pred)*100)\n",
    "print(confusion_matrix(y_test,rfc_pred))\n",
    "print(classification_report(y_test,rfc_pred))\n",
    "print('\\n')\n",
    "print(\"Results from the tunned parameters:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,RFC_pred)*100)\n",
    "print(confusion_matrix(y_test,RFC_pred))\n",
    "print(classification_report(y_test,RFC_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Neural Networks (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data should be normalized before training the neural network model. This is because the NN model might not converge before the max number of iterations allowed. Also, the multi-layer perception is sensitive to scaling the features. (source: https://www.kdnuggets.com/2016/10/beginners-guide-neural-networks-python-scikit-learn.html/2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df.drop('y',axis=1))\n",
    "scaled_features = scaler.transform(df.drop('y',axis=1))\n",
    "\n",
    "df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])\n",
    "\n",
    "X_nn = df_feat.loc[:,]\n",
    "y_nn = df['y']\n",
    "X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_nn,y_nn, test_size=0.30,random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with 2 layers with number of neurons:(36,36)\n",
    "mlp = MLPClassifier(max_iter=1000,random_state=101, hidden_layer_sizes=(36,36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_clf = mlp.fit(X_train_nn,y_train_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nn_clf.predict(X_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy is \", accuracy_score(y_test,predictions)*100)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tunning the NN parameters using the GridSearchCV method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'max_iter': [2000],\n",
    "    'hidden_layer_sizes': [(32,32), (20,20), (47,47)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam','lbfgs'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant'],\n",
    "    'random_state': [101]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_nn, y_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameter set\n",
    "print('Best parameters found:\\n', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_nn = MLPClassifier(activation = 'tanh',alpha = 0.0001, learning_rate= 'constant', solver = 'sgd', random_state=101, hidden_layer_sizes=(32,32), max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_nn.fit(X_train_nn, y_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test_nn , clf.predict(X_test_nn)\n",
    "\n",
    "print(\"Results from the default parameters:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,predictions)*100)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(\"\\n\")\n",
    "print(\"Results from the tunned parameters:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_true,y_pred)*100)\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Creating plots of the models on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting best two features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized Data for Nural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testnn_df =pd.DataFrame(X_test_nn, columns=df.columns[:-1]) \n",
    "y_testnn_df = pd.DataFrame(y_test_nn, columns = ['y'])\n",
    "X_testnn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df =pd.DataFrame(X_test, columns=df.columns[:-1]) \n",
    "y_test_df = pd.DataFrame(y_test, columns = ['y'])\n",
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_test_df.columns, dt_clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test_df.iloc[:, ]\n",
    "X = X[['pdays','nr.employed']]\n",
    "y= y_test_df['y']\n",
    "\n",
    "\n",
    "\n",
    "label = ['Decision Tree', 'Random Forests']\n",
    "clf_list = [clf_gini, RFC]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "for clf, label, grd in zip(clf_list, label, grid):        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    plt.title(label)\n",
    "    plt.xlabel('pdays')\n",
    "    plt.ylabel('nr.employed')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_testnn_df.iloc[:, ]\n",
    "X = X[['pdays','nr.employed']]\n",
    "y= y_testnn_df['y']\n",
    "\n",
    "\n",
    "label = ['Neural Network']\n",
    "clf_list = [mlp_nn]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "\n",
    "for clf, label, grd in zip(clf_list, label, grid):        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    plt.title(label)\n",
    "    plt.xlabel('pdays')\n",
    "    plt.ylabel('nr.employed')\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test_df.iloc[:, ]\n",
    "X = X[['nr.employed','euribor3m']]\n",
    "y= y_test_df['y']\n",
    "\n",
    "\n",
    "\n",
    "label = ['Decision Tree', 'Random Forests']\n",
    "clf_list = [clf_gini, RFC]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "for clf, label, grd in zip(clf_list, label, grid):        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    plt.title(label)\n",
    "    plt.xlabel('nr.employed')\n",
    "    plt.ylabel('euribor3m')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_testnn_df.iloc[:, ]\n",
    "X = X[['nr.employed','euribor3m']]\n",
    "y= y_testnn_df['y']\n",
    "\n",
    "\n",
    "label = ['Neural Network']\n",
    "clf_list = [mlp_nn]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "\n",
    "for clf, label, grd in zip(clf_list, label, grid):        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    plt.title(label)\n",
    "    plt.xlabel('nr.employed')\n",
    "    plt.ylabel('euribor3m')\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test_df.iloc[:, ]\n",
    "X = X[['pdays','euribor3m']]\n",
    "y= y_test_df['y']\n",
    "\n",
    "\n",
    "label = ['Decision Tree', 'Random Forests']\n",
    "clf_list = [clf_gini, RFC]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "\n",
    "for clf, label, grd in zip(clf_list, label, grid):        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    plt.title(label)\n",
    "    plt.xlabel('pdays')\n",
    "    plt.ylabel('euribor3m')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_testnn_df.iloc[:, ]\n",
    "X = X[['pdays','euribor3m']]\n",
    "y= y_testnn_df['y']\n",
    "\n",
    "\n",
    "label = ['Neural Network']\n",
    "clf_list = [mlp_nn]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "\n",
    "for clf, label, grd in zip(clf_list, label, grid):        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    plt.title(label)\n",
    "    plt.xlabel('pdays')\n",
    "    plt.ylabel('euribor3m')\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce a table with the true/false positive/negative metrics as well as accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report for Decision Tree:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,y_pred_dt)*100)\n",
    "print(confusion_matrix(y_test,y_pred_dt))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred_dt))\n",
    "\n",
    "print(\"Classification Report for Random Forests:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_test,RFC_pred)*100)\n",
    "print(confusion_matrix(y_test,RFC_pred))\n",
    "print(classification_report(y_test,RFC_pred))\n",
    "\n",
    "\n",
    "print(\"Classification Report for Neural Network:\")\n",
    "print(\"Accuracy is \", accuracy_score(y_true,y_pred)*100)\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ('Decision Tree', 'Random Forest', 'Neural Network')\n",
    "ind = ['Accuracies (%)', 'True Positive', 'False Positive', 'False Negative', 'True Negative']\n",
    "accuracies = [accuracy_score(y_test,y_pred_dt)*100,accuracy_score(y_test,RFC_pred)*100,accuracy_score(y_true,y_pred)*100]\n",
    "true_negative = [confusion_matrix(y_test,y_pred_dt)[0][0], confusion_matrix(y_test,RFC_pred)[0][0],confusion_matrix(y_true,y_pred)[0][0]]\n",
    "false_negative = [confusion_matrix(y_test,y_pred_dt)[0][1],confusion_matrix(y_test,RFC_pred)[0][1], confusion_matrix(y_true,y_pred)[0][1]]\n",
    "false_positive = [confusion_matrix(y_test,y_pred_dt)[1][0],confusion_matrix(y_test,RFC_pred)[1][0],confusion_matrix(y_true,y_pred)[1][0]]\n",
    "true_positive = [confusion_matrix(y_test,y_pred_dt)[1][1],confusion_matrix(y_test,RFC_pred)[1][1],confusion_matrix(y_true,y_pred)[1][1]]\n",
    "\n",
    "arr1 = np.array([accuracies, true_positive,false_positive,false_negative,true_negative]) \n",
    "table_1 = pd.DataFrame(arr1, index = ind, columns = algorithms)\n",
    "\n",
    "table_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "\n",
    "algorithms = ('Decision Tree', 'Random Forest', 'Neural Network')\n",
    "x_axis = np.arange(len(algorithms))\n",
    "dt_accuracy = accuracy_score(y_test,y_pred_dt)*100\n",
    "rf_accuracy = accuracy_score(y_test,RFC_pred)*100\n",
    "nn_accuracy = accuracy_score(y_true,y_pred)*100\n",
    "performance = [dt_accuracy,rf_accuracy,nn_accuracy]\n",
    " \n",
    "plt.bar(x_axis, performance, align='center', alpha=0.5)\n",
    "plt.xticks(x_axis, algorithms)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracies for the Classification Algorithms')\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ('Decision Tree', 'Random Forest', 'Neural Network')\n",
    "x_axis = np.arange(len(algorithms))\n",
    "dt_truep = confusion_matrix(y_test,y_pred_dt)[0][0]\n",
    "rf_truep = confusion_matrix(y_test,RFC_pred)[0][0]\n",
    "nn_truep = confusion_matrix(y_true,y_pred)[0][0]\n",
    "truep = [dt_truep,rf_truep,nn_truep]\n",
    " \n",
    "plt.bar(x_axis, truep, align='center', alpha=0.5)\n",
    "plt.xticks(x_axis, algorithms)\n",
    "plt.ylabel('True negative')\n",
    "plt.title('True negative values')\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ('Decision Tree', 'Random Forest', 'Neural Network')\n",
    "x_axis = np.arange(len(algorithms))\n",
    "dt_falsep = confusion_matrix(y_test,y_pred_dt)[0][1]\n",
    "rf_falsep = confusion_matrix(y_test,RFC_pred)[0][1]\n",
    "nn_falsep = confusion_matrix(y_true,y_pred)[0][1]\n",
    "falsep = [dt_falsep,rf_falsep,nn_falsep]\n",
    " \n",
    "plt.bar(x_axis, falsep, align='center', alpha=0.5)\n",
    "plt.xticks(x_axis, algorithms)\n",
    "plt.ylabel('False Negative')\n",
    "plt.title('False negative values for the classificiation algorithms')\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ('Decision Tree', 'Random Forest', 'Neural Network')\n",
    "x_axis = np.arange(len(algorithms))\n",
    "dt_falseN = confusion_matrix(y_test,y_pred_dt)[1][0]\n",
    "rf_falseN = confusion_matrix(y_test,RFC_pred)[1][0]\n",
    "nn_falseN = confusion_matrix(y_true,y_pred)[1][0]\n",
    "falseN = [dt_falseN,rf_falseN,nn_falseN]\n",
    " \n",
    "plt.bar(x_axis, falseN, align='center', alpha=0.5)\n",
    "plt.xticks(x_axis, algorithms)\n",
    "plt.ylabel('False Positive')\n",
    "plt.title('False positive values for the classificiation algorithms')\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ('Decision Tree', 'Random Forest', 'Neural Network')\n",
    "x_axis = np.arange(len(algorithms))\n",
    "dt_falseP = confusion_matrix(y_test,y_pred_dt)[1][1]\n",
    "rf_falseP = confusion_matrix(y_test,RFC_pred)[1][1]\n",
    "nn_falseP = confusion_matrix(y_true,y_pred)[1][1]\n",
    "falseP = [dt_falseP,rf_falseP,nn_falseP]\n",
    " \n",
    "plt.bar(x_axis, falseP, align='center', alpha=0.5)\n",
    "plt.xticks(x_axis, algorithms)\n",
    "plt.ylabel('True Postive')\n",
    "plt.title('True postive values for the classificiation algorithms')\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Parameter Selection and Classification (for dataset B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data loading and preprocessing using the Z-score normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9  ...  48  49  50  51  52  53  54  55  \\\n",
       "0   1   2   1   2   1   2   3   3   3   3 ...   3   2   3   4   2   2   2   2   \n",
       "1   3   3   4   2   1   2   2   4   3   2 ...   1   4   3   4   4   4   1   3   \n",
       "2   4   1   4   4   4   4   1   1   2   1 ...   1   2   1   1   4   2   2   4   \n",
       "3   1   4   1   1   3   3   4   4   3   4 ...   1   3   3   4   1   3   3   4   \n",
       "4   3   4   4   3   1   1   4   4   4   1 ...   3   1   3   2   1   4   2   1   \n",
       "5   3   2   3   1   2   3   4   3   1   4 ...   2   2   2   3   4   2   2   2   \n",
       "6   4   2   1   4   2   4   4   4   2   3 ...   4   3   3   4   2   2   1   2   \n",
       "7   3   3   4   3   1   3   4   3   4   1 ...   4   2   2   1   1   4   3   3   \n",
       "8   1   3   4   3   3   1   1   4   2   1 ...   2   1   3   2   2   2   2   1   \n",
       "9   1   3   1   1   3   1   1   2   1   1 ...   2   4   2   2   2   1   1   3   \n",
       "\n",
       "   56  57  \n",
       "0   1   1  \n",
       "1   4   1  \n",
       "2   4   1  \n",
       "3   2  -1  \n",
       "4   1  -1  \n",
       "5   2  -1  \n",
       "6   4   1  \n",
       "7   1   1  \n",
       "8   1   1  \n",
       "9   1   1  \n",
       "\n",
       "[10 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataB = pd.read_csv('DataDNA.csv', sep = ',', header= None)\n",
    "df2 = pd.DataFrame(dataB)\n",
    "print(df2.shape)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(2200, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9  ...  48  49  50  51  52  53  54  55  \\\n",
       "0   1   2   1   2   1   2   3   3   3   3 ...   3   2   3   4   2   2   2   2   \n",
       "1   3   3   4   2   1   2   2   4   3   2 ...   1   4   3   4   4   4   1   3   \n",
       "2   4   1   4   4   4   4   1   1   2   1 ...   1   2   1   1   4   2   2   4   \n",
       "3   1   4   1   1   3   3   4   4   3   4 ...   1   3   3   4   1   3   3   4   \n",
       "4   3   4   4   3   1   1   4   4   4   1 ...   3   1   3   2   1   4   2   1   \n",
       "\n",
       "   56  57  \n",
       "0   1   1  \n",
       "1   4   1  \n",
       "2   4   1  \n",
       "3   2  -1  \n",
       "4   1  -1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df2.isnull().sum().sum())\n",
    "# df2.iloc[:,:-1].head()\n",
    "print(df2.shape)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1137\n",
       "-1    1063\n",
       "Name: 57, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[57].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[57] = df2[57].map({1: 1, -1: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3   -1\n",
       "4   -1\n",
       "Name: 57, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[57].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/engineer/anaconda3/envs/ece657A/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/engineer/anaconda3/envs/ece657A/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.352898</td>\n",
       "      <td>-0.487479</td>\n",
       "      <td>-1.372441</td>\n",
       "      <td>-0.470994</td>\n",
       "      <td>-1.431156</td>\n",
       "      <td>-0.448281</td>\n",
       "      <td>0.405564</td>\n",
       "      <td>0.415676</td>\n",
       "      <td>0.396645</td>\n",
       "      <td>0.392611</td>\n",
       "      <td>-1.454242</td>\n",
       "      <td>-0.500168</td>\n",
       "      <td>-1.369434</td>\n",
       "      <td>0.381451</td>\n",
       "      <td>1.253160</td>\n",
       "      <td>-0.579766</td>\n",
       "      <td>-1.471189</td>\n",
       "      <td>-0.599369</td>\n",
       "      <td>-0.583351</td>\n",
       "      <td>-0.598913</td>\n",
       "      <td>-1.437523</td>\n",
       "      <td>-1.477642</td>\n",
       "      <td>-0.611451</td>\n",
       "      <td>0.332324</td>\n",
       "      <td>-1.495711</td>\n",
       "      <td>1.418861</td>\n",
       "      <td>-0.570943</td>\n",
       "      <td>0.015762</td>\n",
       "      <td>-1.448819</td>\n",
       "      <td>1.821169</td>\n",
       "      <td>-0.776737</td>\n",
       "      <td>-0.237862</td>\n",
       "      <td>-1.131068</td>\n",
       "      <td>1.535688</td>\n",
       "      <td>-0.569710</td>\n",
       "      <td>-0.376354</td>\n",
       "      <td>-1.395430</td>\n",
       "      <td>-0.483853</td>\n",
       "      <td>-1.401924</td>\n",
       "      <td>-1.399702</td>\n",
       "      <td>-0.496609</td>\n",
       "      <td>-0.455196</td>\n",
       "      <td>-1.402111</td>\n",
       "      <td>1.391803</td>\n",
       "      <td>-0.432450</td>\n",
       "      <td>0.472744</td>\n",
       "      <td>0.497988</td>\n",
       "      <td>1.424712</td>\n",
       "      <td>0.453914</td>\n",
       "      <td>-0.464630</td>\n",
       "      <td>0.513026</td>\n",
       "      <td>1.383572</td>\n",
       "      <td>-0.452656</td>\n",
       "      <td>-0.400135</td>\n",
       "      <td>-0.458416</td>\n",
       "      <td>-0.417566</td>\n",
       "      <td>-1.392249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.459203</td>\n",
       "      <td>0.433082</td>\n",
       "      <td>1.360021</td>\n",
       "      <td>-0.470994</td>\n",
       "      <td>-1.431156</td>\n",
       "      <td>-0.448281</td>\n",
       "      <td>-0.495689</td>\n",
       "      <td>1.322008</td>\n",
       "      <td>0.396645</td>\n",
       "      <td>-0.509943</td>\n",
       "      <td>-0.530114</td>\n",
       "      <td>-0.500168</td>\n",
       "      <td>-1.369434</td>\n",
       "      <td>-0.549950</td>\n",
       "      <td>1.253160</td>\n",
       "      <td>1.232002</td>\n",
       "      <td>0.325434</td>\n",
       "      <td>-0.599369</td>\n",
       "      <td>-1.475822</td>\n",
       "      <td>-0.598913</td>\n",
       "      <td>-1.437523</td>\n",
       "      <td>0.346607</td>\n",
       "      <td>0.307396</td>\n",
       "      <td>-1.488629</td>\n",
       "      <td>-0.600319</td>\n",
       "      <td>0.496979</td>\n",
       "      <td>0.392304</td>\n",
       "      <td>1.749605</td>\n",
       "      <td>-0.318134</td>\n",
       "      <td>-1.360333</td>\n",
       "      <td>0.082831</td>\n",
       "      <td>0.675396</td>\n",
       "      <td>-1.131068</td>\n",
       "      <td>-1.391967</td>\n",
       "      <td>0.324910</td>\n",
       "      <td>-1.292259</td>\n",
       "      <td>1.360356</td>\n",
       "      <td>-0.483853</td>\n",
       "      <td>-0.477671</td>\n",
       "      <td>1.376149</td>\n",
       "      <td>-0.496609</td>\n",
       "      <td>-1.391112</td>\n",
       "      <td>-1.402111</td>\n",
       "      <td>-1.357643</td>\n",
       "      <td>0.493928</td>\n",
       "      <td>0.472744</td>\n",
       "      <td>0.497988</td>\n",
       "      <td>0.490475</td>\n",
       "      <td>-1.356803</td>\n",
       "      <td>1.404083</td>\n",
       "      <td>0.513026</td>\n",
       "      <td>1.383572</td>\n",
       "      <td>1.424521</td>\n",
       "      <td>1.435731</td>\n",
       "      <td>-1.374415</td>\n",
       "      <td>0.497419</td>\n",
       "      <td>1.369651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.365253</td>\n",
       "      <td>-1.408039</td>\n",
       "      <td>1.360021</td>\n",
       "      <td>1.317075</td>\n",
       "      <td>1.342890</td>\n",
       "      <td>1.371309</td>\n",
       "      <td>-1.396943</td>\n",
       "      <td>-1.396986</td>\n",
       "      <td>-0.491065</td>\n",
       "      <td>-1.412496</td>\n",
       "      <td>1.318143</td>\n",
       "      <td>-0.500168</td>\n",
       "      <td>-0.476237</td>\n",
       "      <td>-1.481351</td>\n",
       "      <td>0.343575</td>\n",
       "      <td>1.232002</td>\n",
       "      <td>-0.572878</td>\n",
       "      <td>-0.599369</td>\n",
       "      <td>-0.583351</td>\n",
       "      <td>-1.505108</td>\n",
       "      <td>-1.437523</td>\n",
       "      <td>-1.477642</td>\n",
       "      <td>-1.530297</td>\n",
       "      <td>-1.488629</td>\n",
       "      <td>0.295072</td>\n",
       "      <td>-1.346787</td>\n",
       "      <td>1.355552</td>\n",
       "      <td>0.882684</td>\n",
       "      <td>-1.448819</td>\n",
       "      <td>-1.360333</td>\n",
       "      <td>0.082831</td>\n",
       "      <td>1.588655</td>\n",
       "      <td>0.627483</td>\n",
       "      <td>0.559803</td>\n",
       "      <td>1.219529</td>\n",
       "      <td>-0.376354</td>\n",
       "      <td>-1.395430</td>\n",
       "      <td>-1.404680</td>\n",
       "      <td>-0.477671</td>\n",
       "      <td>1.376149</td>\n",
       "      <td>1.367795</td>\n",
       "      <td>-1.391112</td>\n",
       "      <td>-0.485426</td>\n",
       "      <td>-1.357643</td>\n",
       "      <td>-1.358828</td>\n",
       "      <td>-1.361537</td>\n",
       "      <td>1.414020</td>\n",
       "      <td>-1.378000</td>\n",
       "      <td>-1.356803</td>\n",
       "      <td>-0.464630</td>\n",
       "      <td>-1.316240</td>\n",
       "      <td>-1.376046</td>\n",
       "      <td>1.424521</td>\n",
       "      <td>-0.400135</td>\n",
       "      <td>-0.458416</td>\n",
       "      <td>1.412405</td>\n",
       "      <td>1.369651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.352898</td>\n",
       "      <td>1.353642</td>\n",
       "      <td>-1.372441</td>\n",
       "      <td>-1.365028</td>\n",
       "      <td>0.418208</td>\n",
       "      <td>0.461514</td>\n",
       "      <td>1.306817</td>\n",
       "      <td>1.322008</td>\n",
       "      <td>0.396645</td>\n",
       "      <td>1.295164</td>\n",
       "      <td>-0.530114</td>\n",
       "      <td>0.400298</td>\n",
       "      <td>1.310158</td>\n",
       "      <td>-0.549950</td>\n",
       "      <td>-0.566010</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>0.325434</td>\n",
       "      <td>0.311904</td>\n",
       "      <td>0.309119</td>\n",
       "      <td>1.213478</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>1.258732</td>\n",
       "      <td>-0.611451</td>\n",
       "      <td>0.332324</td>\n",
       "      <td>0.295072</td>\n",
       "      <td>1.418861</td>\n",
       "      <td>1.355552</td>\n",
       "      <td>-0.851159</td>\n",
       "      <td>-0.318134</td>\n",
       "      <td>-0.299832</td>\n",
       "      <td>-1.636305</td>\n",
       "      <td>-1.151121</td>\n",
       "      <td>1.506759</td>\n",
       "      <td>0.559803</td>\n",
       "      <td>-1.464329</td>\n",
       "      <td>1.455456</td>\n",
       "      <td>1.360356</td>\n",
       "      <td>1.357802</td>\n",
       "      <td>1.370835</td>\n",
       "      <td>1.376149</td>\n",
       "      <td>-1.428812</td>\n",
       "      <td>-1.391112</td>\n",
       "      <td>1.347943</td>\n",
       "      <td>-1.357643</td>\n",
       "      <td>-1.358828</td>\n",
       "      <td>1.389885</td>\n",
       "      <td>-0.418044</td>\n",
       "      <td>-0.443763</td>\n",
       "      <td>-1.356803</td>\n",
       "      <td>0.469726</td>\n",
       "      <td>0.513026</td>\n",
       "      <td>1.383572</td>\n",
       "      <td>-1.391244</td>\n",
       "      <td>0.517798</td>\n",
       "      <td>0.457583</td>\n",
       "      <td>1.412405</td>\n",
       "      <td>-0.471615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.459203</td>\n",
       "      <td>1.353642</td>\n",
       "      <td>1.360021</td>\n",
       "      <td>0.423041</td>\n",
       "      <td>-1.431156</td>\n",
       "      <td>-1.358075</td>\n",
       "      <td>1.306817</td>\n",
       "      <td>1.322008</td>\n",
       "      <td>1.284354</td>\n",
       "      <td>-1.412496</td>\n",
       "      <td>-1.454242</td>\n",
       "      <td>0.400298</td>\n",
       "      <td>1.310158</td>\n",
       "      <td>1.312852</td>\n",
       "      <td>1.253160</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>-1.471189</td>\n",
       "      <td>0.311904</td>\n",
       "      <td>-1.475822</td>\n",
       "      <td>1.213478</td>\n",
       "      <td>1.265512</td>\n",
       "      <td>1.258732</td>\n",
       "      <td>0.307396</td>\n",
       "      <td>1.242800</td>\n",
       "      <td>1.190464</td>\n",
       "      <td>1.418861</td>\n",
       "      <td>0.392304</td>\n",
       "      <td>-0.851159</td>\n",
       "      <td>-0.318134</td>\n",
       "      <td>-0.299832</td>\n",
       "      <td>-1.636305</td>\n",
       "      <td>-1.151121</td>\n",
       "      <td>1.506759</td>\n",
       "      <td>-1.391967</td>\n",
       "      <td>-1.464329</td>\n",
       "      <td>0.539551</td>\n",
       "      <td>-1.395430</td>\n",
       "      <td>1.357802</td>\n",
       "      <td>1.370835</td>\n",
       "      <td>-0.474418</td>\n",
       "      <td>0.435593</td>\n",
       "      <td>0.480721</td>\n",
       "      <td>-1.402111</td>\n",
       "      <td>-1.357643</td>\n",
       "      <td>-1.358828</td>\n",
       "      <td>0.472744</td>\n",
       "      <td>-0.418044</td>\n",
       "      <td>1.424712</td>\n",
       "      <td>0.453914</td>\n",
       "      <td>-1.398986</td>\n",
       "      <td>0.513026</td>\n",
       "      <td>-0.456173</td>\n",
       "      <td>-1.391244</td>\n",
       "      <td>1.435731</td>\n",
       "      <td>-0.458416</td>\n",
       "      <td>-1.332552</td>\n",
       "      <td>-1.392249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.352898 -0.487479 -1.372441 -0.470994 -1.431156 -0.448281  0.405564   \n",
       "1  0.459203  0.433082  1.360021 -0.470994 -1.431156 -0.448281 -0.495689   \n",
       "2  1.365253 -1.408039  1.360021  1.317075  1.342890  1.371309 -1.396943   \n",
       "3 -1.352898  1.353642 -1.372441 -1.365028  0.418208  0.461514  1.306817   \n",
       "4  0.459203  1.353642  1.360021  0.423041 -1.431156 -1.358075  1.306817   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.415676  0.396645  0.392611 -1.454242 -0.500168 -1.369434  0.381451   \n",
       "1  1.322008  0.396645 -0.509943 -0.530114 -0.500168 -1.369434 -0.549950   \n",
       "2 -1.396986 -0.491065 -1.412496  1.318143 -0.500168 -0.476237 -1.481351   \n",
       "3  1.322008  0.396645  1.295164 -0.530114  0.400298  1.310158 -0.549950   \n",
       "4  1.322008  1.284354 -1.412496 -1.454242  0.400298  1.310158  1.312852   \n",
       "\n",
       "         14        15        16        17        18        19        20  \\\n",
       "0  1.253160 -0.579766 -1.471189 -0.599369 -0.583351 -0.598913 -1.437523   \n",
       "1  1.253160  1.232002  0.325434 -0.599369 -1.475822 -0.598913 -1.437523   \n",
       "2  0.343575  1.232002 -0.572878 -0.599369 -0.583351 -1.505108 -1.437523   \n",
       "3 -0.566010  0.326118  0.325434  0.311904  0.309119  1.213478  0.364500   \n",
       "4  1.253160  0.326118 -1.471189  0.311904 -1.475822  1.213478  1.265512   \n",
       "\n",
       "         21        22        23        24        25        26        27  \\\n",
       "0 -1.477642 -0.611451  0.332324 -1.495711  1.418861 -0.570943  0.015762   \n",
       "1  0.346607  0.307396 -1.488629 -0.600319  0.496979  0.392304  1.749605   \n",
       "2 -1.477642 -1.530297 -1.488629  0.295072 -1.346787  1.355552  0.882684   \n",
       "3  1.258732 -0.611451  0.332324  0.295072  1.418861  1.355552 -0.851159   \n",
       "4  1.258732  0.307396  1.242800  1.190464  1.418861  0.392304 -0.851159   \n",
       "\n",
       "         28        29        30        31        32        33        34  \\\n",
       "0 -1.448819  1.821169 -0.776737 -0.237862 -1.131068  1.535688 -0.569710   \n",
       "1 -0.318134 -1.360333  0.082831  0.675396 -1.131068 -1.391967  0.324910   \n",
       "2 -1.448819 -1.360333  0.082831  1.588655  0.627483  0.559803  1.219529   \n",
       "3 -0.318134 -0.299832 -1.636305 -1.151121  1.506759  0.559803 -1.464329   \n",
       "4 -0.318134 -0.299832 -1.636305 -1.151121  1.506759 -1.391967 -1.464329   \n",
       "\n",
       "         35        36        37        38        39        40        41  \\\n",
       "0 -0.376354 -1.395430 -0.483853 -1.401924 -1.399702 -0.496609 -0.455196   \n",
       "1 -1.292259  1.360356 -0.483853 -0.477671  1.376149 -0.496609 -1.391112   \n",
       "2 -0.376354 -1.395430 -1.404680 -0.477671  1.376149  1.367795 -1.391112   \n",
       "3  1.455456  1.360356  1.357802  1.370835  1.376149 -1.428812 -1.391112   \n",
       "4  0.539551 -1.395430  1.357802  1.370835 -0.474418  0.435593  0.480721   \n",
       "\n",
       "         42        43        44        45        46        47        48  \\\n",
       "0 -1.402111  1.391803 -0.432450  0.472744  0.497988  1.424712  0.453914   \n",
       "1 -1.402111 -1.357643  0.493928  0.472744  0.497988  0.490475 -1.356803   \n",
       "2 -0.485426 -1.357643 -1.358828 -1.361537  1.414020 -1.378000 -1.356803   \n",
       "3  1.347943 -1.357643 -1.358828  1.389885 -0.418044 -0.443763 -1.356803   \n",
       "4 -1.402111 -1.357643 -1.358828  0.472744 -0.418044  1.424712  0.453914   \n",
       "\n",
       "         49        50        51        52        53        54        55  \\\n",
       "0 -0.464630  0.513026  1.383572 -0.452656 -0.400135 -0.458416 -0.417566   \n",
       "1  1.404083  0.513026  1.383572  1.424521  1.435731 -1.374415  0.497419   \n",
       "2 -0.464630 -1.316240 -1.376046  1.424521 -0.400135 -0.458416  1.412405   \n",
       "3  0.469726  0.513026  1.383572 -1.391244  0.517798  0.457583  1.412405   \n",
       "4 -1.398986  0.513026 -0.456173 -1.391244  1.435731 -0.458416 -1.332552   \n",
       "\n",
       "         56  \n",
       "0 -1.392249  \n",
       "1  1.369651  \n",
       "2  1.369651  \n",
       "3 -0.471615  \n",
       "4 -1.392249  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Z-score normalized values\n",
    "normalized_df = df2.iloc[:,:-1]\n",
    "std_scale = preprocessing.StandardScaler().fit(normalized_df)\n",
    "df_std = std_scale.transform(normalized_df)\n",
    "df_zscore = pd.DataFrame(df_std)\n",
    "df_zscore.columns =  normalized_df.columns\n",
    "df_zscore.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Parameter Selection: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 1, Accuracies: [0.69902913 0.69480519 0.69155844 0.72077922 0.72312704]\n",
      "For k= 3, Accuracies: [0.70226537 0.73376623 0.70779221 0.73701299 0.71661238]\n",
      "For k= 5, Accuracies: [0.72815534 0.73376623 0.75       0.72402597 0.71009772]\n",
      "For k= 7, Accuracies: [0.73786408 0.74675325 0.72727273 0.73051948 0.70032573]\n",
      "For k= 31, Accuracies: [0.69902913 0.74350649 0.70454545 0.73376623 0.71009772]\n",
      "\n",
      "\n",
      "Mean of accuracy scores: [0.7058598038374136, 0.7194898357179752, 0.729209053493548, 0.728547053022876, 0.7181890055802962]\n",
      "\n",
      "\n",
      "Length of list 5\n",
      "Max of list 0.729209053493548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross-validated accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4VeW1+PHvyhwICQlJIDnMEGYwAQRURFARHAm2Wqjttb29Pzvptdbb1rbWqtX2tra1vW2vrbe11daKrZVBtOKEWluJDAlzwhAQkhCmMISZJOv3x96BQ8ywITk50/o8Tx5y9nTW9shZ7Pd91/uKqmKMMcZcqJhgB2CMMSa8WSIxxhjTLpZIjDHGtIslEmOMMe1iicQYY0y7WCIxxhjTLpZIjDHGtIslEmOMMe1iicQYY0y7xAXy4iIyE/g5EAv8VlX/u8n+x4Fp7ssuQLaqdheRfsCL7nnxwC9U9dfuOeOAPwDJwCvA3dpGeX5mZqb279+/o27LGGOiwsqVK/epalZbx0mgpkgRkVhgEzAdqACWA3NVdUMLx98FFKjqv4tIghvbSRFJAdYBl6pqlYh8ANwNLMNJJP+jqn9vLZbx48frihUrOuzejDEmGojISlUd39ZxgWzamgBsUdVyVT0FzANmtXL8XOA5AFU9paon3e2JjXGKSA6Qqqrvu08hzwCFgboBY4wxbQtkIvEBO/1eV7jbPsJtyhoAvOW3rY+IrHGv8UNVrXLPr/ByTWOMMZ0jkIlEmtnWUjvaHOAFVa0/c6DqTlUdAwwGbheRnudzTRG5Q0RWiMiKvXv3nmfoxhhjvApkIqkA+vi97g1UtXDsHNxmrabcJ5H1wOXuNXt7uaaqPqmq41V1fFZWm31FxhhjLlAgE8lyIE9EBrid53OARU0PEpGhQDrwvt+23iKS7P6eDlwGlKnqLqBWRCaJiAD/BiwM4D0YY4xpQ8CG/6pqnYjcCSzBGcb7lKquF5GHgRWq2phU5gLzmgzhHQ78REQUpznrx6q61t33Rc4O//27+2OMMSZIAjb8N5TY8F9jjDl/oTD81wSYqvLnoh28uXE3R0/WBTscY0yUCmhluwms1RWH+NZ8p8UvPlYY1y+dKUOymJKXxYicVGJimhvkZowxHcsSSRhbVr4fgCduG0vJzoO8s2kvP3q1jB+9WkZmSgKTB2cyZUgWl+dlkdUtMcjRGmMilSWSMFZUvp9BWV25dnQO147O4ZvXDWfP4RP8Y/M+3t28l3c372NBiTM6ekROKpcPyeSKvCzG9U8nMS42yNEbYyKFJZIwVd+grNh+gBvzc8/Znp2axMfG9eZj43rT0KBs2HWYdzbt5d1Ne/ndP7bxm3fKSY6PZdLADKcZbEgWAzO74oymNsaY82eJJExtqDpM7ck6Jg7IaPGYmBhhlC+NUb40vjxtMEdO1rFs637naWXTXpaWORX/vu7JTBmSyZS8LC4dnElacnxn3YYxJgJYIglTRduc/pFJA3t4PiclMY6rR/Tk6hE9Adix/9iZpPLS6l0898FOYgQmDujB7AIfM0f3IjXJkooxpnVWRxKm/uPpFWzZU8vbX5vW9sEenK5vcDrsy/ayeE0V2/cfIzEuhqtH9GR2vo8pQ7JIiLPR4sZEE691JPZEEoYaGpTl22u4dlSvDrtmfGwMF/fP4OL+Gdx7zRBKdh5kQXElL63ZxctrdpHeJZ4bxuQye6yPgj7drU/FGHOGJZIwtLH6MIeOn2biwJb7R9pDRCjom05B33Tuv2EE727ay/ziSv6yYid/XPYh/Xp0oTDfR2GBjwGZXQMSgzEmfFgiCUNF5TWA05cRaPGxMVw1vCdXDe9J7YnTvLqumgUllfzPW5v5+ZubKejbndkFPq4fnUOPFKtVMSYaWSIJQ0Xb9tMnI5nc7smd+r7dkuK5ZXwfbhnfh+pDJ1hYUsn84koeWLieh1/awBVDsigs8DF9RE+S4q1OxZhoYYkkzDQ0KB9sq+Gq4T2DGkevtCQ+f8UgPn/FIDbuOsyCkkoWFlfxZukeUhLjuHZUL2YX+Jg4sAexNlWLMRHNEkmY2bznCAeOnW61fqSzDc9JZXhOKl+fMYyi8v3ML67k7+uq+evKCnqlJjErP5fCAh/Dc1KDHaoxJgAskYSZC6kf6SyxMcKlgzO5dHAm3yscxRsbdzN/VSW/e28bv3m3nGG9ujG7wMdN+bnkpHVus5wxJnAskYSZovIafN2T6Z0e2l/ESfGx3DAmlxvG5LL/yEleXruL+cWV/ODvpfz3q6VcMrAHhQU+rh3Vi25W9GhMWLOCxDCiqlz86BtMycvip5/ID3Y4F2T7vqMscDvpP3SLHqeP6MnsAqfoMT7Wih6NCRVWkBiBtu49wr4jpwJWP9IZ+md25StXD+Huq/Iobix6XF3F4jW7yOiawI1jcigs8JFvRY/GhA1LJGFkWSfWjwSaiDC2bzpj+6bzHb+ix3nLd/L0+x/Sv0cXCgt8FOb76G9Fj8aENEskYaRoWw09UxPp16NLsEPpUP5Fj4cbix6LK/n5m5v52RtO0ePNBT6uH5NLRteEYIdrjGnCEkmYUFWKyvczaWCPiG7ySU2K59bxfbh1fB+qDh5n0eoq5q+q5DsL1/PQSxuYOtQperx6uBU9GhMqLJGEie37j7Gn9mRY94+cr9zuyXzhikF8obHosbiSBSWVvLHRr+hxrI9JA3rY+vTGBJElkjBR5K7PHgn9IxfiTNHjzGEsa1L0mJOWxE35ucwu8DGslxU9GtPZLJGEiaJtNWSmJDIoK7o7nmNjhMsGZ3LZ4Ey+N8spelxQXHlmGeHhOanMLsjlpot89EpLCna4xkQFSyRhQFVZVr6fiQMzIrp/5HwlJ8Ry40W53HiRU/S4eI1T9Pj9V0r5wd9LuXRQDwrzfcy0okdjAsoSSRjYWXOcXYdOMCmE5tcKNT1SErn90v7cfml/tu07eqY/5WsvrOE7C9cxfUQvZhfkcnmeFT0a09EskYSBZe78WhNDcH6tUDQgsyv3TB/CV67OY9UOp+hx8ZoqXlpdZUWPxgSAJZIwUFReQ0bXBPKyU4IdSlgREcb1S2dcv3OLHp9zix4HZHZ1V3rMpV+P6O57MqY9LJGEgaJt+5nQ3/pH2iMhLoarR/Tk6hFu0ePaauYXV/KzNzfx+BubGNu40qMVPRpz3iyRhLjKg8epOHCcz00eEOxQIkZqUjy3XtyHWy9uqegxm9kFPq4anm1Fj8Z4YIkkxDXWj4Ti+iORoLHo8fNTBrJxV62z0mNJJW9s3E23xDiuG+30p0wckGFFj8a0wBJJiCsqr6F7l3iG9uwW7FAimogwIjeVEbmpfGPmMN7f6hQ9Ll5TxfMrdpKTlsSsfB+zC3wM7WWfhTH+LJGEuGXb9nNxf/vXcGeKjREm52UyOS+TRwpH8bpb9Ph//yjn1+9sZXhOKje7Kz32TLWiR2MCOqBeRGaKSJmIbBGR+5rZ/7iIlLg/m0TkoLs9X0TeF5H1IrJGRD7hd84fRGSb33nhucKTB9WHTvDh/mMhtT57tElOiOWmi3J56jMXU/Stq3jwxhEkxMXw6CsbmfSDN/nUb4t4YWUFR07WBTtUY4ImYCskikgssAmYDlQAy4G5qrqhhePvAgpU9d9FZAigqrpZRHKBlcBwVT0oIn8AFqvqC15jCdcVEheWVHL3vBIW3zWZUb60YIdj/JTvPcKCkioWFFeyo+YYSfExTB/Ri5sLfEzOy7SiRxMRQmGFxAnAFlUtdwOaB8wCmk0kwFzguwCquqlxo6pWicgeIAs4GMB4Q86y8hq6JcUxPMcmIgw1A7NS+Or0IdxzdR6rdhxw+1N28dLqKnp0TeDGi3IpLPBxUe80G7ZtIl4gE4kP2On3ugKY2NyBItIPGAC81cy+CUACsNVv86Mi8gDwJnCfqp7sqKBDSZHbPxJr/SMhyyl6zGBcvwweuGEk72zay/ziCv78wQ7+8K/tDMzsemalx74RtiCZMY0CmUia+/ZrqR1tDvCCqtafcwGRHOCPwO2q2uBu/iZQjZNcngS+ATz8kTcXuQO4A6Bv374XEn9Q7ak9Qfneo8y5uE+wQzEeJcTFMH1ET6aP6Mmh46d5dZ0zieRPX9/ET1/fxLh+6RQW+LhhdA7pVvRoIkibDbki8mMRGXkB164A/L8FewNVLRw7B3iuyfumAi8D96vqssbtqrpLHSeB3+M0oX2Eqj6pquNVdXxWVtYFhB9cH2yLnPXZo1FacjyfuLgv8+64hH/edyXfmDmM2hOn+c6CdUz4/hv8v2dW8MraXZw4Xd/2xYwJcV6eSEqBJ0UkDueL+zlVPeThvOVAnogMACpxksUnmx4kIkOBdOB9v20JwHzgGVX9a5Pjc1R1lzgNz4XAOg+xhJ2i8hpSEuMYmWv9I+HO1z2ZL04dxBeuGMgGd6XHhSVVvL5hN92S4rhulBU9mvDWZiJR1d8Cv3W/8D8LrBGRfwL/p6pLWzmvTkTuBJYAscBTqrpeRB4GVqjqIvfQucA8PXf42K3AFKCHiHzG3fYZVS0BnhWRLJymsxLgC+dxv2FjWfl+xvVLJ85G/0QMEWFkbhojc9O479rhvL91Py8WV5wpesxNS2JWgVP0OMQKUE0Y8TT81x3KewNOIukD/AWYDBxV1TkBjbADhNvw3/1HTjLukTf4+syhfGnq4GCHYwLs2Kk6Xt/gFD2+u3kf9Q3KiJxUZhf4mJWfS7YVPZog6bDhvyLyU+AmnBFS31fVD9xdPxSRsvaFaZpj/SPRpUtCHLPyfczK97G39iSL1zj1KY++spEf/H0jlw3OpDDfx4xRvUhJtMkoTOjx8n/lOpwO72PN7Gu2o9u0T9G2GpLjYxnT24oQo01Wt0Q+e9kAPnvZALbuPcLC4krml1Ry719X8+0Fa5kxsheFBT4uH5xpzZ4mZHhJJAeAMwtei0h3YKqqLvDY6W7OU2P/iFVHR7dBWSl89Zqh3DN9CCs/PFv0uLCkisyUBG4Yk8vsAh9jrOjRBFmbfSQiUqKq+U22FatqQUAj60Dh1Edy8NgpCr73OvdOH8KdV+YFOxwTYk7VNfB22R4WlFTyxsY9nKprYGBWV2bn+ygs8NEnw4oeTcfpyClSmvtnsTXUBsgH22pQtfXZTfMS4mK4ZmQvrhnZi0PHT/P3tU7R409e38RPXt/EeLfo8XorejSdyEtCWOF2uP8KpzL9LpxJFE0AFG2rITEuxvpHTJvSkuOZM6Evcyb0pfLgcRaWVDJ/VSX3L1jHQy+tZ+rQbG4u8DFtmK30aALLSyK5C/gO8DxO7cZrwJcDGVQ0W1a+n7F900mMs7/4xjtf92S+NHUwX7xiEOur3KLH1WeLHq93V3qcYGvbmADwUpB4FPjIWiKm4x06fpoNuw5z91XWN2IujIgwypfGKF8a37xuOP/auo/5qypZtLqKect34uuezKx8p5M+z4oeTQfxUkeSBXwdGAmcqYxS1SsDGFdUWrHd7R+x+hHTAWJjhMvzsrg8L4tH3KLH+cWV/Obdcv737a2MzHWKHm+6yIoeTft4adp6FqdZ6wac6UhuB/YGMqhoVbSthoTYGAr6dg92KCbCNFf0OL+4kkde3sj3X3GKHmcX+JgxshddrejRnCcvw39Xquo4EVmjqmPcbe+o6hWdEmEHCJfhv7N++R6J8bH85fOXBDsUEyW27DnidNIXV1Jx4DjJ8bFcM7KnFT0aoGOH/552/9wlItfjTAXfuz3BmY86crKOdVWH+fLUQcEOxUSRwdkp3HvNUL46fQgr3KLHl/2KHm+8yOlPGe2zokfTMi+J5BERSQPuBX4BpAL3BDSqKLRiew31DWr1IyYoRISL+2dwcf8MvnvjCN4u28uC4kqeXbaD3/9zuxU9mla1mkjcWX/zVHUxcAiY1ilRRaGibTXExwpj+6YHOxQT5RLjYpkxshczRvbi0LHTvLLu3KLHi/ufLXrs3sWKHo23PpKlqhrWCSQc+khm/+8/iRHhb1+8NNihGNOsigPHWFjidNJv2XOEhNgYpg3LYrZb9Gi1T5GnI/tI/iUiv8QZuXW0caOqrmpHfMbPsVN1rK04xB1TBgY7FGNa1Du9C1+eNpgvTXWKHue7Kz0uWb+b1KQ4rh+TQ2G+j4ut6DHqeEkkjf9EfthvmwJWR9JBVn54gDrrHzFh4pyix2uH8a+t+5lfXMmC4iqe+8ApeiwscDrpB2db0WM08FLZHtbNWuGgqLyG2BhhXD/rHzHhJS42hilDspgyJItHCs8WPT7x9lZ+tXQro3ypFOZb0WOk89JH8kBz21X14ea2h6JQ7yO55df/4nS9suDLlwU7FGM6xJ7aE7y0ehcLiitZW3mIGIHLBmdy81gf14ywosdw0ZF9JEf9fk/CqXDfeKGBmXOdOF3P6p2H+Ozk/sEOxZgOk90tic9NHsDnJg9gy55aFhQ7nfT3PL+a5Ph1zHCLHidb0WNE8NK09RP/1yLyY2BRwCKKMqt2HOBUfQOTbH4tE6EGZ3fjv2Y4RY8rdxzgxVWVvLymigUlVWSmJHKTW/Q4ypdqRY9h6kKeL7sANryogywrryFGYHx/6x8xkS0m5mzR44M3jWBpqVP0+KdlH/LUP7cxKKsrswuc+cCs6DG8eJn9dy3OKC2AWCCLc0dwmXYoKt/PyNw0uiXFBzsUYzpNYlwsM0f1YuYop+jx5bVOf8qPX9vEj1/bxIT+GWeKHtO62N+NUOels72f38s6YLeq1gU0qg4Wqp3tJ07XM+ah1/i3Sf24/4YRwQ7HmKDbWXOMRaureHFVBVv3HrWixyDryM72HGC9qta6F04RkZGqWtTeIKPd6p0HOVXXYPUjxrj6ZJwtelxX6RQ9LlrtX/To9KeM75duRY8hxEsieQIY6/f6WDPbzAUo2laDCEzonxHsUIwJKSLC6N5pjO6dxreuG8Y/t+5nQXElC4oree6DHX5Fj70ZnJ0S7HCjnpdEIurX/qWqDSJig8A7QNG2/QzvlWptwMa0Ii42hiuGZHGFW/T42oZq5hdXnSl6HO1Lo7DAx40X5ZDdzYoeg8FLQigXkf/EeQoB+BJQHriQosOpugZWfniAuRP6BjsUY8JG18Q4Zhf0ZnZB73OKHr+3eAOPvryBy/Oc/pRrRvakS4L9e7ezePkv/QXgf4D7cUZvvQncEcigosHayoOcON1g67Mbc4H8ix43765lQYkz39dXni+hS4IzFX5hgY/LBvWwoscA81KQuAeY0wmxRJVl5TUATBhg/SPGtFdez258bcYw7p0+lOXba1hQUsniNc46KlndzhY9jsy1osdA8FJH8jRwt6oedF+nAz9R1X8PdHCRbFn5fob27EZGV1sYyJiOEhMjTBzYg4kDe/DdG0fydtke5hdX8sz72/nde9sYnJ3C7AJnEkkreuw4Xpq2xjQmEQBVPSAiBQGMKeKdrnf6Rz4+rnewQzEmYiXFxzJzVA4zR+Vw8NipM0WPjy0p47ElZUzon8HssT6uG2VFj+3lJZHEiEi6qh4AEJEMj+eZFqyrPMSxU/VMsvoRYzpF9y4J3DaxH7dN7MfOmmMsLKnkxeJKvvniWr67cD1XDsumsMDHtGFZVvR4AbwkhJ/grJL4gvv6FuDRwIUU+Yq2Wf+IMcHSJ6MLd16Zx5enDWZt5SHmF1fy0uoqXl1fTVpyPNePyWF2gY9xfa3o0Ssvne3PiMhKYBogwM2qusHLxUVkJvBznDm6fquq/91k/+PudcGZDDJbVbuLSD7OcONUoB54VFWfd88ZAMwDMoBVwKdV9ZSXeEJFUfl+BmenkJmSGOxQjIlaIsKY3t0Z07s7375uOO9t2ceC4krmr6rkz0U76J2eTGG+j8ICnxU9tqHNubbOHCiSjbMeCQCquqON42OBTcB0oAJYDsxtKQmJyF1Agar+u4gMcd5CN4tILrASGK6qB0XkL8CLqjpPRH4NrFbVJ5q7ZqNQmmurvkHJf+g1bsrP5dHZo4MdjjGmiSMn63htfTXziyv555Z9NCiM6Z1GYb6PGy/KJatb9PwD0OtcW20OrhaRm0RkM7ANeAfYDvzdQwwTgC2qWu4+McwDZrVy/FzgOQBV3aSqm93fq4A9QJY44/auBBqb2Z4GCj3EEjI2VB2m9mSdza9lTIhKSYzj5rG9+ePnJrLsm1dx//XDqW9QHl68gUk/eJPbn/qABcWVHDsVVnPXBpSXPpLvAZOAN1S1QESm4Xzpt8UH7PR7XQFMbO5Ad4bhAcBbzeybACQAW4EewEG/2Ycr3Pdp7pp34BZO9u0bOtXjy8r3AzDJ+keMCXnZqUn8x+UD+Y/LB7Jpdy0LiitZWHK26HGmW/R4aZQXPXpJJKdVdb+IxIhIjKouFZEfejivuV6qltrR5gAvqGr9ORcQyQH+CNzuzvHl+Zqq+iTwJDhNWx7i7RRF2/YzILMr2ak2J5Ax4WRIz258feYw/uuac4seX7SiR0+J5KCIpADvAs+KyB6cdUnaUgH08XvdG6hq4dg5wJf9N4hIKvAycL+qLnM37wO6i0ic+1TS2jVDTn2D8sG2Gq4bnRPsUIwxF6hp0ePS0nOLHvOyUygs8DErP5fe6dFR9OglkcwCjgP3ALcBaXhbIXE5kOeOsqrESRafbHqQiAwF0oH3/bYlAPOBZ1T1r43bVVVFZCnwcZw+l9uBhR5iCQml1Yc5fKLO6keMiRBJ8bFcOzqHa0c7RY+L15xb9DhxQAazC3xcOzqHtOTILXr0PGrrgi4uch3wM5zhv0+p6qMi8jCwQlUXucc8CCSp6n1+530K+D2w3u9yn1HVEhEZyNnhv8XAp1T1ZGtxhMqorWfe384DC9fzr/uuJLd7crDDMcYEyI79TtHj/OJKyvc5Kz1eNdwpepw6NHyKHr2O2gpoIgkVoZJIvvniGl5dV82q70yPujZUY6KRqrKm4mzR4/6jp0hLjueGxqLHfukh/V3QkUvtmg5SWl3L0F7dQvp/HGNMxxERLurTnYv6dOfb158tevzbqgqeLdpBn4yzRY+DssK36NESSSdpaFA2Vddyy/g+bR9sjIk48bExTBuazbSh2Rw5WceSddUsKKnkV0u38Iu3tjCmdxqzC5yix3Cb9aLFRCIia2l5uC6qOiYgEUWoyoPHOXqqnqG9ugU7FGNMkKUkxvGxcb352Lje7D58gpdWV/HiqkoeemkDj7y8kcvzMp2VHkf0Ijkh9PtTWnsiucH9s3FY7h/dP28DjgUsoghVWl0LYInEGHOOnn5Fj2XVzkqPC4sruXteCV0TYpkxqhezC3xcOiiT2BCdRLLFRKKqHwKIyGWqepnfrvtE5J94GwJsXGXVhwGnqMkYY5oztFc3vjFzGF+7ZigfbK9hQXElL6/dxYurKsluLHoc62NETmgVPXrpI+kqIpNV9T0AEbkU6BrYsCJPaXUtfTKSSUm0biljTOtiYoRJA3swaWAPHrxpJG+5RY9Pv7+d3763jSE9G4seffhCoJTAy7fa54CnRCQNp8/kEGDL7J6nsupahvZMDXYYxpgwkxQfy3Wjc7hudA4HjjorPc4vruRHr5bxo1dDo+jxfKaRT3WPPxTYkDpesOtITtbVM+KBJXzxikH814yhQYvDGBM5duw/xgK36HHbvqMkxMVw9fBsCvN9TB2aTUJc+yeR7LA6EhHpCXwfyFXVa0VkBHCJqv6u3VFGia17jlLfoNbRbozpMH17dOE/r8rjrisHs7riEAvcosdX1lbTvUs814/O4eaxPsb2DXzRo5eU9QdgCZDrvt4EfCVQAUWist1OR/swSyTGmA4mIuT36c6DN41k2beu4vefuZgpeVn8bVUFH3vifdZUBL4RyUsfSaaq/kVEvgmgqnUiUt/WSeas0upaEmJj6J9pYxSMMYETHxvDtGHZTBvmFD0uLd3DmN5pAX9fL4nkqIj0wC1OFJFJOB3uxqOy6loGZacQH8UL3xhjOldKYhw3XpTb9oEdwEsi+SqwCBjk1o9kAbcENKoIU1Zda1PHG2MilpdEsh64AhiKs+phGd76Vgxw6Nhpdh06YR3txpiI5SUhvK+qdaq6XlXXqepp/BahMq0r221ToxhjIltrkzb2AnxAsogUcHYN9lQgOtaP7ACNU6PYiC1jTKRqrWlrBvAZnHXRf+q3vRb4VgBjiiil1bWkJsXRKzUp2KEYY0xAtDZp49PA0yLyMVX9WyfGFFHKqmsZ1iu0JlgzxpiO1GZnu6r+TUSuB0YCSX7bbfbfNqgqZbtrKcz3BTsUY4wJmDY720Xk18AngLtw+kluAfoFOK6IUHXoBLUn6qyj3RgT0byM2rpUVf8NOKCqDwGXALZerAfW0W6MiQZeEslx989jIpILnAYGBC6kyNG4KuIQSyTGmAjmpSBxsYh0Bx4DVuFMlfLbgEYVIcqqa/F1TyY1KThrBBhjTGfw0tn+PffXv4nIYiApHNckCYay6lrrHzHGRLzWChJvbmUfqvpiYEKKDKfrG9i69wjThmUHOxRjjAmo1p5IbnT/zAYuBd5yX08D3gYskbSifO9RTterdbQbYyJeawWJnwVwm7NGqOou93UO8KvOCS98lbojtqxpyxgT6byM2urfmERcu4EhAYonYpRV1xIXIwzMTAl2KMYYE1BeRm29LSJLgOdwRmzNAZYGNKoIUFZdy6CsFBLibMZ9Y0xk8zJq60634/1yd9OTqjo/sGGFv9LqWsb1Sw92GMYYE3BenkgaR2hZ57pHtSdOU3nwOJ+c2DfYoRhjTMC1Nvz3PVWdLCK1uOu1N+4CVFVTAx5dmNrkLmZlI7aMMdGgtVFbk90/7dvwPDVOjWIjtowx0aDFnmARyWjtx8vFRWSmiJSJyBYRua+Z/Y+LSIn7s0lEDvrte1VEDrrDj/3P+YOIbPM7L/98brgzlFXX0i0xDl/35GCHYowxAddaH8lKnCat5lZkUmBgaxcWkVicepPpQAWwXEQWqeqGMxdRvcfv+LuAAr9LPIazpO/nm7n811T1hdbeP5hKq2sZ0qubLWZljIkKrTVttXeG3wnAFlUtBxCRecAsYEMLx88Fvuv3/m+KyNR2xtDpVJWy6lquH5MT7FCMMaZTeCpyEJF0EZkgIlMafzyc5gN2+r2ucLc1d/2NYhAMAAAR1klEQVR+OFPTv9Xc/mY8KiJr3KaxRI/ndIrdh09y6Php62g3xkQNLysk/gfwLrAEeMj980EP126pSaw5c4AXVLXew3W/CQwDLgYygG80++Yid4jIChFZsXfvXg+X7RgbG6dG6WmJxBgTHbw8kdyN86X9oapOw+nH8PLNXMG5Kyn2BqpaOHYOTuV8m1R1lzpOAr/HaUJr7rgnVXW8qo7PysrycukOUVbdOPTXRkcbY6KDl0RyQlVPAIhIoqqWAkM9nLccyBORASKSgJMsFjU9SESGAunA+14CdieNRJye7EJgnZfzOktZdS29UpNI62KLWRljooOXyvYKd4XEBcDrInKAlp8szlDVOhG5E6cpLBZ4SlXXi8jDwApVbUwqc4F5qnpOs5eI/AOnCStFRCqAz6nqEuBZEcnCaTorAb7g6U47SaktZmWMiTJe5tqa7f76oIgsBdKAV71cXFVfAV5psu2BJq8fbOHcy1vYfqWX9w6G0/UNbN1zhCl5mcEOxRhjOk2biUREfg48r6r/UtV3OiGmsLV931FO1TfYE4kxJqp46SNZBdzvVqc/JiLjAx1UuLKpUYwx0ajNRKKqT6vqdTijozYBPxSRzQGPLAyVVdcSGyMMzrbFrIwx0eN8Vl0ajNP53R8oDUg0Ya60upYBmV1JjIsNdijGGNNpvBQkNj6BPAysB8ap6o0BjywMle0+bM1axpio42X47zbgElXdF+hgwtmRk3XsrDnOreP6tH2wMcZEEC99JL9uTCIi8mDAIwpTjYtZ2ROJMSbanE8fCcBNAYkiAtjUKMaYaHW+icQW2GhBWXUtXRJi6Z1ui1kZY6LL+SaScQGJIgKUVh9mSM9uxMRYrjXGRBcvo7Z+JCKpIhKPM9fWPhH5VCfEFjYaF7ManmP9I8aY6OPlieQaVT0M3IAzNfwQ4GsBjSrM7K09yYFjp20NEmNMVPKSSBrnQ78OeE5VawIYT1g6OzWKdbQbY6KPlzqSl0SkFDgOfMmdwv1EYMMKL2dHbNkTiTEm+nipI7kPuAQYr6qngaPArEAHFk5Kq2vJ7pZIeteEYIdijDGdzktn+y1AnarWi8j9wJ+A3IBHFkZsahRjTDTz0kfyHVWtFZHJwAzgaeCJwIYVPuoblM27j1izljEmanlJJPXun9cDT6jqQsDacFzb9x/lZF2DdbQbY6KWl0RSKSK/AW4FXhGRRI/nRQXraDfGRDsvCeFWYAkwU1UPAhlYHckZpdW1xAi2mJUxJmp5GbV1DNgKzBCRO4FsVX0t4JGFibLqw/TP7EpSvC1mZYyJTl5Gbd0NPAtkuz9/EpG7Ah1YuCirrrVmLWNMVPNSkPg5YKKqHgVnxUTgfeAXgQwsHBw7VceHNceYXdA72KEYY0zQeOkjEc6O3ML93aa4BTbvPoKqLWZljIluXp5Ifg8Uich893Uh8LvAhRQ+bMSWMcZ4SCSq+lMReRuYjPMk8llVLQ50YOGgtLqW5PhY+mZ0CXYoxhgTNK0mEhGJAdao6ihgVeeEFD7Kdh9mSM8UW8zKGBPVWu0jUdUGYLWI9O2keMJKWXWt9Y8YY6Kelz6SHGC9iHyAM/MvAKp6U8CiCgP7jpxk35FTNjWKMSbqeUkkDwU8ijBkHe3GGONoMZGIyGCgp6q+02T7FKAy0IGFurOrIloiMcZEt9b6SH4G1Daz/Zi7L6qVVR8mMyWBzJTEYIdijDFB1Voi6a+qa5puVNUVQP+ARRQmrKPdGGMcrSWSpFb2JXu5uIjMFJEyEdkiIvc1s/9xESlxfzaJyEG/fa+KyEERWdzknAEiUiQim0XkeRHp9LVRGhqUTbuPMLSndbQbY0xriWS5iPy/phtF5HPAyrYuLCKxwK+Aa4ERwFwRGeF/jKreo6r5qpqPM3fXi367HwM+3cylfwg8rqp5wAGcucA61Y6aYxw/XW8d7cYYQ+ujtr4CzBeR2zibOMbjrI4428O1JwBbVLUcQETmAbOADS0cPxf4buMLVX1TRKb6HyAiAlwJfNLd9DTwIJ289K91tBtjzFktJhJV3Q1cKiLTgFHu5pdV9S2P1/YBO/1eVwATmztQRPoBA4C2rt0DOKiqdX7X9HmMp8OUVdciAkN6WiIxxhgvc20tBZZewLWbmzdEWzh2DvCCqta3sP+8rykidwB3APTt27GF+WW7D9MvowvJCbaYlTHGBHLt9Qqgj9/r3kBVC8fOAZ7zcM19QHcRaUyALV5TVZ9U1fGqOj4rK8tjyN6U2ogtY4w5I5CJZDmQ546ySsBJFouaHiQiQ4F0nMWyWqWqivN09HF30+3Awg6L2IMTp+vZvu+oTY1ijDGugCUStx/jTmAJsBH4i6quF5GHRcR/nq65wDw3SZwhIv8A/gpcJSIVIjLD3fUN4KsisgWnz6RT10bZsucIDWpToxhjTCMvc21dMFV9BXilybYHmrx+sIVzL29heznOiLCgsBFbxhhzrkA2bUWksurDJMbF0L9H12CHYowxIcESyXkqra4lr2cKsbaYlTHGAJZIzltZda1NjWKMMX4skZyHA0dPsaf2pHW0G2OMH0sk58E62o0x5qMskZyHsurDgA39NcYYf5ZIzkPZ7lrSu8ST1c0WszLGmEaWSM7Dxl3O1CjOJMTGGGPAEolnzmJWtQyzqVGMMeYclkg8qjhwnGOn6q2j3RhjmrBE4lGp29FuicQYY85licSjMnfory1mZYwx57JE4lHp7lr6ZCSTkhjQeS6NMSbsWCLxyKZGMcaY5lki8eBkXT3b9h21QkRjjGmGJRIPtuw5Qn2DWke7McY0wxKJB40d7fZEYowxH2WJxIOy6loSYmPon2mLWRljTFOWSDwora5lUHYK8bH2n8sYY5qyb0YPyqprrVnLGGNaYImkDYeOnab68AnraDfGmBZYImmDTY1ijDGts0TShrLdNmLLGGNaY4mkDaXVtaQmxdErNSnYoRhjTEiyRNIGp6M91RazMsaYFlgiaYWqsqm61vpHjDGmFZZIWlF58Di1J+sskRhjTCsskbTCpkYxxpi2WSJpRWnjYlaWSIwxpkWWSFpRVl2Lr3syqUnxwQ7FGGNCli3314phOd3I7Z4c7DCMMSakWSJpxZemDg52CMYYE/KsacsYY0y7WCIxxhjTLgFNJCIyU0TKRGSLiNzXzP7HRaTE/dkkIgf99t0uIpvdn9v9tr/tXrPxvOxA3oMxxpjWBayPRERigV8B04EKYLmILFLVDY3HqOo9fsffBRS4v2cA3wXGAwqsdM894B5+m6quCFTsxhhjvAvkE8kEYIuqlqvqKWAeMKuV4+cCz7m/zwBeV9UaN3m8DswMYKzGGGMuUCATiQ/Y6fe6wt32ESLSDxgAvOXx3N+7zVrfkRZmUxSRO0RkhYis2Lt374XegzHGmDYEMpE09wWvLRw7B3hBVes9nHubqo4GLnd/Pt3cBVX1SVUdr6rjs7KyziNsY4wx5yOQiaQC6OP3ujdQ1cKxczjbrNXquapa6f5ZC/wZpwnNGGNMkIhqSw8J7bywSBywCbgKqASWA59U1fVNjhsKLAEGqBuM29m+EhjrHrYKGAccBrqr6j4RicdJPm+o6q/biGUv8GGTzZnAvgu/w5ASKfcSKfcBdi+hKlLupbPuo5+qttmkE7BRW6paJyJ34iSJWOApVV0vIg8DK1R1kXvoXGCe+mU0Va0Rke/hJB+Ah91tXYElbhKJBd4A/s9DLB/5DyEiK1R1fHvuMVREyr1Eyn2A3UuoipR7CbX7COgUKar6CvBKk20PNHn9YAvnPgU81WTbUZwnE2OMMSHCKtuNMca0SzQnkieDHUAHipR7iZT7ALuXUBUp9xJS9xGwznZjjDHRIZqfSIwxxnSAqEskbU0kGU5EZLuIrHWr/MNq7jEReUpE9ojIOr9tGSLyujtR5+sikh7MGL1q4V4eFJFKv8lFrwtmjF6ISB8RWSoiG0VkvYjc7W4Pu8+llXsJx88lSUQ+EJHV7r085G4fICJF7ufyvIgkBC3GaGracieS3ITfRJLAXP+JJMOJiGwHxqtq2I2LF5EpwBHgGVUd5W77EVCjqv/tJvl0Vf1GMOP0ooV7eRA4oqo/DmZs50NEcoAcVV0lIt1warkKgc8QZp9LK/dyK+H3uQjQVVWPuKUP7wF3A18FXlTVeSLya2C1qj4RjBij7YnkfCeSNAGiqu8CNU02zwKedn9/Gucvfshr4V7CjqruUtVV7u+1wEacOe7C7nNp5V7CjjqOuC/j3R8FrgRecLcH9XOJtkTieSLJMKHAayKyUkTuCHYwHaCnqu4C54sACPe1Zu4UkTVu01fINwf5E5H+OMs6FBHmn0uTe4Ew/FxEJFZESoA9OLOhbwUOqmqde0hQv8uiLZGcz0SS4eAyVR0LXAt82W1iMaHhCWAQkA/sAn4S3HC8E5EU4G/AV1T1cLDjaY9m7iUsPxdVrVfVfJx5BycAw5s7rHOjOivaEsn5TCQZ8lS1cSLLPcB8wn8Cy91u23ZjG/eeIMdzwVR1t/uXvwFnGp+w+GzcNvi/Ac+q6ovu5rD8XJq7l3D9XBqp6kHgbWAS0N2d0xCC/F0WbYlkOZDnjnZIwJl1eFEb54QkEenqdiLizkF2DbCu9bNC3iKgcVnl24GFQYylXRq/eF2zCYPPxu3U/R2wUVV/6rcr7D6Xlu4lTD+XLBHp7v6eDFyN0+ezFPi4e1hQP5eoGrUF4A73+xlnJ5J8NMghXRARGYjzFALOnGl/Dqd7EZHngKk4s5juxllaeQHwF6AvsAO4RVVDvhO7hXuZitN8osB24PON/QyhSkQmA/8A1gIN7uZv4fQthNXn0sq9zCX8PpcxOJ3psTj/+P+Lqj7sfgfMAzKAYuBTqnoyKDFGWyIxxhjTsaKtacsYY0wHs0RijDGmXSyRGGOMaRdLJMYYY9rFEokxxph2sURiIoKIvC0iM5ps+4qI/G8b5x1pbX8HxJXlztBaLCKXN9n3toiMd3/v787iOqOZazzmzvr62AXGMFVEFvu9fkRElohIohvDCr9940Xkbb/zVERu9Nu/WESmXkgcJnJZIjGR4jmcAlN/c9ztwXQVUKqqBar6j+YOEJHewBLgXlVd0swhnwfGqurXvLyhX7Vzc/u+DVwGFPrVHGSLyLUtnFIBfNvL+5roZYnERIoXgBtEJBHOTNSXC7wnIiki8qaIrBJn/ZaPzPjczL/afykin3F/Hyci77iTYy5pUh3deHw/9z3WuH/2FZF84EfAdeKsfZHcTNy9gNeA+1X1I7MsiMgioCtQJCKfaO593OP+ICI/FZGlwA+b+w8kIvcC1wE3qupxv12PAfc3dw6wGjgkItNb2G+MJRITGVR1P/ABMNPdNAd4Xp2K2xPAbHeCy2nAT9wpNNrkztf0C+DjqjoOeApobgaBX+KsRzIGeBb4H1UtAR5w48hv8uXd6Bngl6r61xbu6ybguHv+8829j9/hQ4CrVfXeZi51GfAF4Fq/KckbvQ+cFJFpzcUAPELLicYYSyQmovg3b/k3awnwfRFZA7yBM912T4/XHAqMAl53p/G+H2eCvKYuAf7s/v5HYLLH678BfFpEung8vrX3+auq1rdw3hac/w7XtLC/xWTR2CTXtI/HmEaWSEwkWQBcJSJjgeTGhY2A24AsYJw7FfduIKnJuXWc+/ehcb8A690ngnxVHa2qLX0Z+/M699CPcOay+mtrfRse3+doK8ftxmnWery5Jw9VfQvnnie1cP6jWF+JaYElEhMx3Cabt3Gan/w72dOAPap62v0S7dfM6R8CI9yRTGk4neQAZUCWiFwCTlOXiIxs5vx/cfZp6Dac5VC9ugc4DPzOQ5PbBb+Pqm4Cbgb+5PbfNPUo8PUWzn0NSAcu8vp+JnpYIjGR5jmcL7t5ftueBca7w1xvA0qbnqSqO3FmuF3jHl/sbj+FM1X3D0VkNVACXNrM+/4n8Fm3+ezTOGtqe+L249wO5OA8obTmgt/Hfa/lwGeBRSIyqMm+V4C9rZz+KM0365koZ7P/GmOMaRd7IjHGGNMulkiMMca0iyUSY4wx7WKJxBhjTLtYIjHGGNMulkiMMca0iyUSY4wx7WKJxBhjTLv8fxDfxTpCqQSNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df_zscore.loc[:,]\n",
    "y = df2[57]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.30,random_state=42)\n",
    "\n",
    "# 5-fold cross-validation with k = [1, 3, 5, 7, 31] for KNN (the n_neighbors parameter)\n",
    "k = [1, 3, 5, 7, 31]\n",
    "k_scores = []\n",
    "\n",
    "for i in k:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "    print(\"For k= {}, Accuracies: {}\".format(i, scores))\n",
    "    \n",
    "\n",
    "print('\\n')\n",
    "print('Mean of accuracy scores:', k_scores)\n",
    "print('\\n')\n",
    "print('Length of list', len(k_scores))\n",
    "print('Max of list', max(k_scores))\n",
    "\n",
    "plt.plot(k, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-validated accuracy')\n",
    "\n",
    "#ref: https://www.ritchieng.com/machine-learning-cross-validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) SVM (RBF Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5-fold cross-validation for SVM\n",
    "# c = [0.1, 0.5, 1, 2, 5,10, 20, 50]\n",
    "# sigma = [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]\n",
    "# svm_scores = []\n",
    "\n",
    "# for i,j in zip(c,sigma):\n",
    "#     svm_clf = SVC(kernel='rbf',C = i, gamma=j)\n",
    "#     scores = cross_val_score(svm, X_train, y_train, cv=5, scoring='accuracy')\n",
    "#     svm_scores.append(scores.mean())\n",
    "# #     print(\"scores = {}\".format(scores))\n",
    "# #     print(\"Maan scores = {}\".format(scores.mean()))\n",
    "    \n",
    "\n",
    "# print('\\n')\n",
    "# print('Mean of accuracy scores:', svm_scores)\n",
    "# print('\\n')\n",
    "# print('Length of list', len(svm_scores))\n",
    "# print('Max of list', max(svm_scores))\n",
    "\n",
    "# plt.plot(k, k_scores)\n",
    "# plt.xlabel('Value of K for KNN')\n",
    "# plt.ylabel('Cross-validated accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.01}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC()\n",
    "param_grid = {'C': [0.1, 0.5, 1, 2, 5,10, 20, 50], 'gamma': [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]}\n",
    "grid = GridSearchCV(SVC(kernel='rbf'),param_grid,cv=5,refit=True)\n",
    "grid.fit(X_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SVM GATHER DATA\n",
    "rbf_svc = SVC(kernel='rbf', gamma=0.01, C=10,probability=True).fit(X_train,y_train)\n",
    "\n",
    "#PREDICT PROBABILITY SCORE = 2D ARRAY FOR EACH PREDICTION\n",
    "predictedprobSVC = rbf_svc.predict_proba(X_test)\n",
    "\n",
    "#GET ROC DATA\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictedprobSVC[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#GRAPH DATA\n",
    "plt.figure()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "#plt.xlim([0.0, 1.0]\n",
    "#plt.ylim([0.0, 1.05])\n",
    "plt.title('SVM Classifier ROC')\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='SVM ROC area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "#ref :https://medium.com/datadriveninvestor/computing-an-roc-graph-with-python-a3aa20b9a3fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
