{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import *\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    validation_curve,\n",
    ")\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "### Data used for preliminary results are downsampled and balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "test_data = \"dataset/test.csv\"\n",
    "df_test = pd.read_csv(test_data, sep=\",\", index_col=\"ID_code\")\n",
    "\n",
    "train_data = \"dataset/train.csv\"\n",
    "df_train = pd.read_csv(train_data, sep=\",\", index_col=\"ID_code\")\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df2_majority = df_train[df_train[\"target\"] == 0]\n",
    "df2_minority = df_train[df_train[\"target\"] == 1]\n",
    "n_samples = df2_minority.target.sum()\n",
    "\n",
    "df2_majority_downsampled = resample(\n",
    "   df2_majority, replace=False, n_samples=n_samples, random_state=99\n",
    ")\n",
    "df_downsampled = pd.concat([df2_majority_downsampled, df2_minority])\n",
    "X_dn = df_downsampled.drop([\"target\"], axis=1)\n",
    "y_dn = df_downsampled[\"target\"]\n",
    "\n",
    "# calculatig the z-score normalization using sklearn\n",
    "std_scale = preprocessing.StandardScaler().fit(df_train.drop([\"target\"], axis=1).values)\n",
    "X_dn_norm = std_scale.transform(X_dn)\n",
    "\n",
    "#use all downsamples samples (40 000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dn_norm, y_dn, test_size=0.2, random_state=101)\n",
    "\n",
    "#reduce size of for cbomputationally intensive algorithms\n",
    "X_trainsmall, _, y_trainsmall, _ = train_test_split(X_train, y_train, test_size=0.8756096, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models using default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_params = {\n",
    "    'C': 0.00010494583820459354, \n",
    "    'solver': 'saga'\n",
    "}\n",
    "clf_logreg = LogisticRegression(random_state=111, penalty='l2', **logreg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB_params = {\n",
    "    'var_smoothing': 7.453943540948982e-11\n",
    "}\n",
    "clf_NB = GaussianNB(**NB_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_params = {\n",
    "    \n",
    "}\n",
    "\n",
    "clf_xgb = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        learning_rate=0.1,\n",
    "        silent=1,\n",
    "        early_stopping=200,\n",
    "        n_estimators=500,\n",
    "        tree_method=\"approx\",\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
