{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bc125f6ffaea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m from sklearn.model_selection import (\n\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\adam\\ECE657A-Data-Modelling\\project\\code\\model_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# let init-time option registration happen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\config_init.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \"\"\"\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m from pandas.core.config import (\n\u001b[0;32m     14\u001b[0m     \u001b[0mis_bool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_instance_factory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_one_of_factory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'compat'"
     ]
    }
   ],
   "source": [
    "from model_utils import *\n",
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    validation_curve,\n",
    ")\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "### Data used for preliminary results are downsampled and balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "test_data = \"dataset/test.csv\"\n",
    "df_test = pd.read_csv(test_data, sep=\",\", index_col=\"ID_code\")\n",
    "\n",
    "train_data = \"dataset/train.csv\"\n",
    "df_train = pd.read_csv(train_data, sep=\",\", index_col=\"ID_code\")\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df2_majority = df_train[df_train[\"target\"] == 0]\n",
    "df2_minority = df_train[df_train[\"target\"] == 1]\n",
    "n_samples = df2_minority.target.sum()\n",
    "\n",
    "df2_majority_downsampled = resample(\n",
    "   df2_majority, replace=False, n_samples=n_samples, random_state=99\n",
    ")\n",
    "df_downsampled = pd.concat([df2_majority_downsampled, df2_minority])\n",
    "X_dn = df_downsampled.drop([\"target\"], axis=1)\n",
    "y_dn = df_downsampled[\"target\"]\n",
    "\n",
    "# calculatig the z-score normalization using sklearn\n",
    "std_scale = preprocessing.StandardScaler().fit(df_train.drop([\"target\"], axis=1).values)\n",
    "X_dn_norm = std_scale.transform(X_dn)\n",
    "\n",
    "#use all downsamples samples (40 000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dn_norm, y_dn, test_size=0.2, random_state=101)\n",
    "\n",
    "#reduce size of for cbomputationally intensive algorithms\n",
    "X_trainsmall, _, y_trainsmall, _ = train_test_split(X_train, y_train, test_size=0.8756096, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models using default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_params = {\n",
    "    'C': 0.00010494583820459354, \n",
    "    'solver': 'saga'\n",
    "}\n",
    "clf_logreg = LogisticRegression(random_state=111, penalty='l2', **logreg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB_params = {\n",
    "    'var_smoothing': 7.453943540948982e-11\n",
    "}\n",
    "clf_NB = GaussianNB(**NB_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_params = {\n",
    "    'colsample_bylevel': 0.01, \n",
    "    'colsample_bytree': 1.0,\n",
    "    'gamma': 0.49999999999999994,\n",
    "    'max_delta_step': 0,\n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 19,\n",
    "    'reg_alpha': 1.0,\n",
    "    'reg_lambda': 1000.0,\n",
    "    'scale_pos_weight': 0.3237122916966163,\n",
    "    'subsample': 1.0,\n",
    "}\n",
    "\n",
    "clf_xgb = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        learning_rate=0.1,\n",
    "        silent=1,\n",
    "        early_stopping=200,\n",
    "        n_estimators=8000,\n",
    "        tree_method=\"approx\",\n",
    "        n_jobs=-1\n",
    "        **xgb_params,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_params = {\n",
    "    'colsample_bylevel': 0.5447321073292221,\n",
    "    'colsample_bytree': 0.689559548843798,\n",
    "    'gamma': 0.01,\n",
    "    'max_bin': 426,\n",
    "    'max_delta_step': 13,\n",
    "    'max_depth': 12,\n",
    "    'min_child_samples': 22,\n",
    "    'min_child_weight': 20,\n",
    "    'reg_alpha': 0.7966900476208586,\n",
    "    'reg_lambda': 0.05905416598434505,\n",
    "    'scale_pos_weight': 0.23497655517415514,\n",
    "    'subsample': 0.9183687205758093,\n",
    "    'subsample_for_bin': 492045,\n",
    "    'subsample_freq': 3,\n",
    "}\n",
    "\n",
    "clf_lgb = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        metric='auc',\n",
    "        tree_method='approx',\n",
    "        learning_rate = 0.1,\n",
    "        silent=1,\n",
    "        n_estimators= 7000,\n",
    "        verbose=0,\n",
    "        n_jobs=-1,\n",
    "        **lgb_params,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Benchmark All Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Logistic Regression\n",
    "\n",
    "model_logreg = clf_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_fig, report = benchmark_model_performance(model_logreg, X_test, y_test)\n",
    "stats_fig.savefig(os.path.join('experiment1-logisticregression.png'), dpi=300, format='png')\n",
    "stats_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Logistic Regression\n",
    "\n",
    "model_NB = clf_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_fig, report = benchmark_model_performance(model_NB, X_test, y_test)\n",
    "stats_fig.savefig(os.path.join('experiment1-naivebayes.png'), dpi=300, format='png')\n",
    "stats_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Logistic Regression\n",
    "\n",
    "model_xgb = clf_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_fig, report = benchmark_model_performance(model_xgb, X_test, y_test)\n",
    "stats_fig.savefig(os.path.join('experiment1-xgb.png'), dpi=300, format='png')\n",
    "stats_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Logistic Regression\n",
    "\n",
    "model_lgb = clf_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_fig, report = benchmark_model_performance(model_lgb, X_test, y_test)\n",
    "stats_fig.savefig(os.path.join('experiment1-lgb.png'), dpi=300, format='png')\n",
    "stats_fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
