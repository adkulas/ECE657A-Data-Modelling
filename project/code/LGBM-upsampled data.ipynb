{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors, linear_model\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score, validation_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import pydot\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = \"dataset/test.csv\"\n",
    "dataA = pd.read_csv(testData, sep = ',' , index_col = 'ID_code')\n",
    "dfTest = pd.DataFrame(dataA)\n",
    "\n",
    "trainData = \"dataset/train.csv\"\n",
    "dataB = pd.read_csv(trainData, sep = ',', index_col = 'ID_code')\n",
    "dfTrain = pd.DataFrame(dataB)\n",
    "\n",
    "sample_submission = \"dataset/sample_submission.csv\"\n",
    "dataC = pd.read_csv(sample_submission, sep = ',', index_col = 'ID_code')\n",
    "df_sample = pd.DataFrame(dataC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_complete = dfTrain.iloc[:,0:1]\n",
    "X_train_complete = dfTrain.drop(['target'], axis=1)\n",
    "\n",
    "print(y_train_complete.shape)\n",
    "print(X_train_complete.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X_train_complete.values, y_train_complete.values,\n",
    "                                                  test_size = .1,\n",
    "                                                  random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "x_train_res, y_train_res = sm.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "bayes_cv_tuner = BayesSearchCV(\n",
    "    estimator = lgb.LGBMRegressor(\n",
    "        objective='binary',\n",
    "        metric='auc',\n",
    "        tree_method='approx',\n",
    "        learning_rate = 0.1,\n",
    "        n_jobs=-1,\n",
    "        silent=1,\n",
    "        n_estimators= 7000,\n",
    "        verbose=0\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        'max_delta_step': (0, 20),\n",
    "        'max_depth': (3, 15),\n",
    "        'max_delta_step': (0, 20),\n",
    "        'min_child_samples': (0, 50),\n",
    "        'max_bin': (100, 1000),\n",
    "        'subsample': (0.01, 1.0, 'uniform'),\n",
    "        'subsample_freq': (0, 10),\n",
    "        'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
    "        'min_child_weight': (10, 20),\n",
    "        'gamma': (1e-2, 0.5, 'log-uniform'),\n",
    "        'subsample_for_bin': (100000, 500000),\n",
    "        'reg_lambda': (1e-4, 1000, 'log-uniform'),\n",
    "        'reg_alpha': (1e-4, 1.0, 'log-uniform'),\n",
    "        'scale_pos_weight': (1e-6, 500, 'log-uniform'),\n",
    "        \n",
    "    },    \n",
    "    scoring = 'roc_auc',\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=3,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    ),\n",
    "    n_jobs = 3,\n",
    "    n_iter = 5,   \n",
    "    verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def status_print(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
    "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner.best_score_, 4),\n",
    "        bayes_cv_tuner.best_params_\n",
    "    ))\n",
    "    # Save all model results\n",
    "    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
    "    all_models.to_csv(clf_name + \"_cv_results.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "result = bayes_cv_tuner.fit(x_train_res, y_train_res, callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred = result.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test_dn.values, lgbm_pred.round())\n",
    "print(cm)\n",
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_test_dn.values,lgbm_pred.round())\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(lgbm_pred.round(), index = df_sample.index, columns = dfTrain.columns[0:1])\n",
    "pred.to_csv('lgbm_UPSampling.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
